import os
import cv2
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp


# --- 1. é…ç½®åƒæ•¸ (Configuration) ---
class CFG:
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # --- æ•¸æ“šè·¯å¾‘ ---
    IMAGE_DIR = 'images/'
    MASK_DIR = 'masks/'

    # --- è¨“ç·´è¶…åƒæ•¸ ---
    EPOCHS = 30
    LEARNING_RATE = 1e-4
    BATCH_SIZE = 4  # å¦‚æžœGPUå…§å­˜ä¸è¶³(out of memory)ï¼Œè«‹æ¸›å°æ­¤å€¼
    VALID_BATCH_SIZE = 8

    # --- æ•¸æ“šè™•ç† ---
    IMG_HEIGHT = 512  # æ ¹æ“šä½ çš„éœ€æ±‚å’Œé¡¯å¡æ€§èƒ½èª¿æ•´
    IMG_WIDTH = 512
    NUM_WORKERS = 4  # å»ºè­°è¨­ç½®ç‚ºCPUæ ¸å¿ƒæ•¸çš„ä¸€åŠå·¦å³

    # --- æ¨¡åž‹åƒæ•¸ ---
    ENCODER = 'mobilenet_v2'
    ENCODER_WEIGHTS = 'imagenet'
    # æˆ‘å€‘çš„ç›®æ¨™é¡žåˆ¥ (ID å¿…é ˆæ˜¯ 0, 1, 2)
    CLASSES = {'background': 0, 'normal_stroke': 1, 'defect_area': 2}
    NUM_CLASSES = len(CLASSES)

    # --- æ•¸æ“šé›†åŠƒåˆ† ---
    VALIDATION_SPLIT = 0.2  # 20% çš„æ•¸æ“šä½œç‚ºé©—è­‰é›†

    # --- è¼¸å‡º ---
    MODEL_OUTPUT_PATH = "best_model_defect_iou.pth"


# --- 2. å‰µå»ºæ•¸æ“šé›†é¡ž (Dataset Class) ---
class FontDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # æ­£å¸¸è®€å–æ‚¨çš„å–®é€šé“ç°åº¦åœ–
        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)

        # ------------------- æ ¸å¿ƒä¿®æ”¹éƒ¨åˆ†ï¼šå‹•æ…‹æ¸…æ´—æ¨™æ³¨é‡ -------------------

        # 1. è®€å–å«æœ‰ [0, 113, 227] ç°åº¦å€¼çš„â€œé«’â€æ¨™æ³¨é‡
        dirty_mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)

        # 2. æº–å‚™ä¸€å¡Šç´”æ·¨çš„ã€å…¨ç‚º 0 çš„ç•«å¸ƒ (é»˜èªæ‰€æœ‰åƒç´ éƒ½æ˜¯èƒŒæ™¯)
        clean_mask = np.zeros_like(dirty_mask, dtype=np.uint8)

        # 3. æ ¹æ“šæ‚¨çš„ check_masks.py è¼¸å‡ºï¼Œå®šç¾©è§£ç¢¼è¦å‰‡
        #    æˆ‘å€‘å°‡åœ¨é€™è£¡æŠŠä¸æ¨™æº–çš„ç°åº¦å€¼ï¼Œæ˜ å°„å›žæ¨™æº–çš„é¡žåˆ¥ ID (0, 1, 2)

        # å°‡ç°åº¦å€¼ç‚º 227 çš„åƒç´  (åŽŸé»ƒè‰² Normal_Stroke)ï¼Œåœ¨æ–°ç•«å¸ƒä¸Šæ¨™è¨˜ç‚º 1
        clean_mask[dirty_mask == 227] = 1  # æ˜ å°„ Normal_Stroke

        # å°‡ç°åº¦å€¼ç‚º 113 çš„åƒç´  (åŽŸç´…è‰² Defect_Area)ï¼Œåœ¨æ–°ç•«å¸ƒä¸Šæ¨™è¨˜ç‚º 2
        clean_mask[dirty_mask == 113] = 2  # æ˜ å°„ Defect_Area

        # (ç°åº¦å€¼ç‚º 0 çš„èƒŒæ™¯åƒç´ ç„¡éœ€è™•ç†ï¼Œå› ç‚º clean_mask é»˜èªå°±æ˜¯ 0)

        # 4. å¾žç¾åœ¨é–‹å§‹ï¼Œæˆ‘å€‘ä½¿ç”¨æ¸…æ´—ä¹¾æ·¨çš„ clean_mask é€²è¡Œå¾ŒçºŒæ‰€æœ‰æ“ä½œ
        mask = clean_mask

        # ------------------------- ä¿®æ”¹çµæŸ -------------------------

        # å°‡å–®é€šé“ç°åº¦åœ–è½‰æ›ç‚º3é€šé“ï¼Œä»¥é©æ‡‰ImageNeté è¨“ç·´çš„éª¨å¹¹ç¶²çµ¡
        image = np.stack([image] * 3, axis=-1)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        # CrossEntropyLoss éœ€è¦ Long é¡žåž‹çš„æ¨™ç±¤
        return image, mask.long()


# --- 3. å®šç¾©æ•¸æ“šå¢žå¼· (Data Augmentation) ---
def get_transforms(is_train=True):
    if is_train:
        # è¨“ç·´é›†çš„å¢žå¼·ç­–ç•¥
        transform = A.Compose([
            A.Resize(CFG.IMG_HEIGHT, CFG.IMG_WIDTH, interpolation=cv2.INTER_NEAREST),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.Rotate(limit=15, p=0.4),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2(),
        ])
    else:
        # é©—è­‰é›†åªéœ€Resizeå’Œæ¨™æº–åŒ–
        transform = A.Compose([
            A.Resize(CFG.IMG_HEIGHT, CFG.IMG_WIDTH, interpolation=cv2.INTER_NEAREST),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2(),
        ])
    return transform


# --- 4. è¨“ç·´å’Œé©—è­‰å‡½æ•¸ ---
def train_fn(loader, model, optimizer, loss_fn, device):
    """å–®å€‹ epoch çš„è¨“ç·´å‡½æ•¸"""
    model.train()
    loop = tqdm(loader, desc="Training")
    running_loss = 0.0

    for images, masks in loop:
        images = images.to(device)
        masks = masks.to(device)

        predictions = model(images)
        loss = loss_fn(predictions, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        loop.set_postfix(loss=loss.item())

    return running_loss / len(loader)


def eval_fn(loader, model, loss_fn, device, num_classes):
    """å–®å€‹ epoch çš„é©—è­‰å‡½æ•¸ï¼ŒåŒ…å«å®Œæ•´çš„æŒ‡æ¨™è¨ˆç®—"""
    model.eval()
    running_loss = 0.0
    total_pixels = 0
    correct_pixels = 0

    # åˆå§‹åŒ–ç”¨æ–¼è¨ˆç®—IoUçš„è¨ˆæ•¸å™¨
    total_tp = torch.zeros(num_classes, device=device)
    total_fp = torch.zeros(num_classes, device=device)
    total_fn = torch.zeros(num_classes, device=device)

    loop = tqdm(loader, desc="Validating")

    with torch.no_grad():
        for images, masks in loop:
            images = images.to(device)
            masks = masks.to(device)

            predictions = model(images)
            loss = loss_fn(predictions, masks)
            running_loss += loss.item()

            # å°‡æ¨¡åž‹è¼¸å‡ºè½‰æ›ç‚ºé æ¸¬çš„é¡žåˆ¥æ¨™ç±¤ (N, H, W)
            pred_labels = torch.argmax(predictions, dim=1)

            # è¨ˆç®—åƒç´ æº–ç¢ºçŽ‡
            correct_pixels += torch.sum(pred_labels == masks).item()
            total_pixels += masks.nelement()

            # ç‚ºè¨ˆç®—IoUç´¯åŠ æ¯å€‹é¡žåˆ¥çš„ TP, FP, FN
            for cls_id in range(num_classes):
                total_tp[cls_id] += torch.sum((pred_labels == cls_id) & (masks == cls_id))
                total_fp[cls_id] += torch.sum((pred_labels == cls_id) & (masks != cls_id))
                total_fn[cls_id] += torch.sum((pred_labels != cls_id) & (masks == cls_id))

    # è¨ˆç®—æ•´å€‹é©—è­‰é›†çš„æœ€çµ‚æŒ‡æ¨™
    avg_loss = running_loss / len(loader)
    avg_accuracy = correct_pixels / total_pixels

    class_iou = {}
    class_names = list(CFG.CLASSES.keys())
    for cls_id in range(num_classes):
        iou = (total_tp[cls_id]) / (total_tp[cls_id] + total_fp[cls_id] + total_fn[cls_id] + 1e-6)
        class_iou[class_names[cls_id]] = iou.item()

    return avg_loss, avg_accuracy, class_iou


# --- 5. ä¸»åŸ·è¡Œæµç¨‹ ---
if __name__ == '__main__':
    print(f"Using device: {CFG.DEVICE}")

    # --- æº–å‚™æ•¸æ“š ---
    all_image_names = sorted([f for f in os.listdir(CFG.IMAGE_DIR) if f.endswith('.png')])
    np.random.seed(42)  # ç‚ºäº†å¯è¤‡ç¾æ€§
    np.random.shuffle(all_image_names)

    split_idx = int(len(all_image_names) * (1 - CFG.VALIDATION_SPLIT))
    train_image_names = all_image_names[:split_idx]
    valid_image_names = all_image_names[split_idx:]

    train_image_paths = [os.path.join(CFG.IMAGE_DIR, name) for name in train_image_names]
    train_mask_paths = [os.path.join(CFG.MASK_DIR, name) for name in train_image_names]
    valid_image_paths = [os.path.join(CFG.IMAGE_DIR, name) for name in valid_image_names]
    valid_mask_paths = [os.path.join(CFG.MASK_DIR, name) for name in valid_image_names]

    train_dataset = FontDataset(train_image_paths, train_mask_paths, transform=get_transforms(is_train=True))
    valid_dataset = FontDataset(valid_image_paths, valid_mask_paths, transform=get_transforms(is_train=False))

    train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=CFG.NUM_WORKERS,
                              pin_memory=True)
    valid_loader = DataLoader(valid_dataset, batch_size=CFG.VALID_BATCH_SIZE, shuffle=False,
                              num_workers=CFG.NUM_WORKERS, pin_memory=True)

    print(f"Training data: {len(train_dataset)} samples")
    print(f"Validation data: {len(valid_dataset)} samples")

    # --- æº–å‚™æ¨¡åž‹ã€æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨ ---
    model = smp.Unet(
        encoder_name=CFG.ENCODER,
        encoder_weights=CFG.ENCODER_WEIGHTS,
        in_channels=3,
        classes=CFG.NUM_CLASSES,
    ).to(CFG.DEVICE)

    loss_fn = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.LEARNING_RATE)

    # --- é–‹å§‹è¨“ç·´ ---
    best_defect_iou = -1.0

    for epoch in range(CFG.EPOCHS):
        print(f"\n--- Epoch {epoch + 1}/{CFG.EPOCHS} ---")

        train_loss = train_fn(train_loader, model, optimizer, loss_fn, CFG.DEVICE)
        val_loss, val_acc, val_iou_by_class = eval_fn(valid_loader, model, loss_fn, CFG.DEVICE, CFG.NUM_CLASSES)

        print(f"Epoch {epoch + 1} Results:")
        print(f"  -> Train Loss: {train_loss:.4f}")
        print(f"  -> Val Loss: {val_loss:.4f}, Val Pixel Accuracy: {val_acc:.4f}")

        # æ‰“å°æ¯å€‹é¡žåˆ¥çš„IoU
        iou_report = ", ".join([f"{name}: {iou:.4f}" for name, iou in val_iou_by_class.items()])
        print(f"  -> Validation IoU -> {iou_report}")

        # æ ¹æ“šç¼ºé™·å€åŸŸçš„IoUä¾†ä¿å­˜æ¨¡åž‹
        current_defect_iou = val_iou_by_class['defect_area']
        if current_defect_iou > best_defect_iou:
            best_defect_iou = current_defect_iou
            torch.save(model.state_dict(), CFG.MODEL_OUTPUT_PATH)
            print(f"ðŸŽ‰ New best model saved to '{CFG.MODEL_OUTPUT_PATH}' (Defect IoU: {best_defect_iou:.4f})")

    print("\n--- Training Finished ---")
    print(f"Best model saved at '{CFG.MODEL_OUTPUT_PATH}' with Defect Area IoU: {best_defect_iou:.4f}")
