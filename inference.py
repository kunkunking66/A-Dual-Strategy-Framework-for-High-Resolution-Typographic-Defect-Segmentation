import os
import cv2
import torch
import numpy as np
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp


# --- 1. é…ç½® (Configuration) ---
class INFERENCE_CFG:
    # --- ã€éœ€è¦æ‚¨ä¿®æ”¹ã€‘ ---
    IMAGE_PATH = "test2.png"
    # æŒ‡å‘æ‚¨ç”¨ã€çµ‚æ¥µè…³æœ¬ã€‘è¨“ç·´å‡ºçš„æ¨¡å‹æ¬Šé‡
    MODEL_PATH = "best_model_compat.pth"
    OUTPUT_PATH = "result2.png"

    # --- ã€æ»‘çª—æ¨ç†çš„æ ¸å¿ƒåƒæ•¸ã€‘ ---
    # çª—å£å¤§å°ï¼Œå¿…é ˆèˆ‡æ‚¨è¨“ç·´æ™‚çš„ CROP_SIZE ä¸€è‡´
    WINDOW_SIZE = 512
    # ç›¸é„°çª—å£çš„é‡ç–Šæ¯”ä¾‹ï¼Œèˆ‡è¨“ç·´ç„¡é—œï¼Œå¯è‡ªè¡Œèª¿æ•´
    OVERLAP_RATIO = 0.25

    # --- ã€æ¨¡å‹åƒæ•¸ï¼Œå¿…é ˆèˆ‡æ‚¨è¨“ç·´æ™‚çš„é…ç½®å®Œå…¨ä¸€è‡´ã€‘ ---
    MODEL_ARCH = "UnetPlusPlus"  # 'UnetPlusPlus' or 'DeepLabV3Plus'
    ENCODER = "resnet101"

    # é¡åˆ¥å®šç¾©
    CLASSES = {"background": 0, "normal_stroke": 1, "defect_area": 2}
    NUM_CLASSES = len(CLASSES)
    DEFECT_CLASS_ID = CLASSES['defect_area']

    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


def build_model(cfg):
    """æ ¹æ“šé…ç½®æ§‹å»ºæ¨¡å‹æ¶æ§‹"""
    if cfg.MODEL_ARCH == "UnetPlusPlus":
        model = smp.UnetPlusPlus(encoder_name=cfg.ENCODER, encoder_weights=None,
                                 in_channels=3, classes=cfg.NUM_CLASSES)
    elif cfg.MODEL_ARCH == "DeepLabV3Plus":
        model = smp.DeepLabV3Plus(encoder_name=cfg.ENCODER, encoder_weights=None,
                                  in_channels=3, classes=cfg.NUM_CLASSES)
    else:
        raise ValueError("MODEL_ARCH must be UnetPlusPlus or DeepLabV3Plus")
    return model


def predict_sliding_window(cfg):
    """ä½¿ç”¨æ»‘çª—æ³•å°å–®å¼µé«˜åˆ†è¾¨ç‡åœ–åƒé€²è¡Œæ¨ç†å’Œå¯è¦–åŒ–"""
    print(f"ä½¿ç”¨è¨­å‚™: {cfg.DEVICE}")
    if not os.path.exists(cfg.IMAGE_PATH) or not os.path.exists(cfg.MODEL_PATH):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°è¼¸å…¥åœ–ç‰‡æˆ–æ¨¡å‹æ–‡ä»¶ã€‚")
        return

    # --- 1. åŠ è¼‰æ¨¡å‹ ---
    print(f"æ­£åœ¨å¾ '{cfg.MODEL_PATH}' åŠ è¼‰æ¨¡å‹...")
    model = build_model(cfg)
    # åŠ è¼‰å–®å¡æˆ–å¤šå¡è¨“ç·´çš„æ¨¡å‹æ¬Šé‡
    state_dict = torch.load(cfg.MODEL_PATH, map_location=cfg.DEVICE)
    if 'module.' in list(state_dict.keys())[0]:  # åˆ¤æ–·æ˜¯å¦ç‚º DataParallel ä¿å­˜çš„æ¬Šé‡
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict)
    model.to(cfg.DEVICE)
    model.eval()

    # --- 2. æº–å‚™åœ–åƒå’Œé è™•ç†æµç¨‹ (å¿…é ˆèˆ‡è¨“ç·´æ™‚çš„é©—è­‰é›†ä¸€è‡´) ---
    transform = A.Compose([
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ])

    original_image_for_viz = cv2.imread(cfg.IMAGE_PATH)
    gray_image_for_model = cv2.imread(cfg.IMAGE_PATH, cv2.IMREAD_GRAYSCALE)
    img_h, img_w = gray_image_for_model.shape
    input_image_3ch = np.stack([gray_image_for_model] * 3, axis=-1)

    # --- 3. æ ¸å¿ƒï¼šæ»‘çª—æ¨ç† ---
    print("ğŸ§  æ­£åœ¨åŸ·è¡Œé«˜ç²¾åº¦æ»‘çª—æ¨ç†...")

    preds_full_size = np.zeros((cfg.NUM_CLASSES, img_h, img_w), dtype=np.float32)
    visits_full_size = np.zeros((img_h, img_w), dtype=np.uint8)
    stride = int(cfg.WINDOW_SIZE * (1 - cfg.OVERLAP_RATIO))

    with torch.no_grad():
        for y1 in tqdm(range(0, img_h, stride), desc="Sliding Window (Rows)"):
            y2 = min(y1 + cfg.WINDOW_SIZE, img_h)
            if y2 - y1 < cfg.WINDOW_SIZE:
                y1 = max(0, y2 - cfg.WINDOW_SIZE)

            for x1 in range(0, img_w, stride):
                x2 = min(x1 + cfg.WINDOW_SIZE, img_w)
                if x2 - x1 < cfg.WINDOW_SIZE:
                    x1 = max(0, x2 - cfg.WINDOW_SIZE)

                patch = input_image_3ch[y1:y2, x1:x2]

                augmented = transform(image=patch)
                image_tensor = augmented['image'].unsqueeze(0).to(cfg.DEVICE)

                # ä½¿ç”¨æ··åˆç²¾åº¦é€²è¡Œæ¨ç†ä»¥åŠ å¿«é€Ÿåº¦
                with torch.cuda.amp.autocast():
                    patch_preds = model(image_tensor)

                # è½‰æ›ç‚º float32 ä»¥ä¾¿ç´¯åŠ 
                patch_preds_cpu = patch_preds.squeeze(0).cpu().to(torch.float32).numpy()

                preds_full_size[:, y1:y2, x1:x2] += patch_preds_cpu
                visits_full_size[y1:y2, x1:x2] += 1

    # --- 4. çµæœèåˆèˆ‡å¾Œè™•ç† ---
    print("ğŸ§© æ­£åœ¨æ‹¼æ¥å’Œèåˆé æ¸¬çµæœ...")
    # å° logits é€²è¡Œå¹³å‡
    avg_preds = preds_full_size / (visits_full_size + 1e-6)
    # ç²å–æœ€çµ‚çš„é æ¸¬æ¨™ç±¤åœ–
    final_pred_mask = np.argmax(avg_preds, axis=0).astype(np.uint8)
    # å‰µå»ºåªåŒ…å«ç¼ºé™·å€åŸŸçš„äºŒå€¼æ©ç¢¼
    defect_mask = (final_pred_mask == cfg.DEFECT_CLASS_ID).astype(np.uint8)

    # --- 5. å¯è¦–åŒ–èˆ‡ä¿å­˜ ---
    if np.sum(defect_mask) == 0:
        print("âœ… åœ¨åœ–ç‰‡ä¸­æœªæª¢æ¸¬åˆ°ä»»ä½•ç¼ºé™·ã€‚")
        cv2.imwrite(cfg.OUTPUT_PATH, original_image_for_viz)
    else:
        print("ğŸ¨ æ­£åœ¨æ¨™è¨˜æª¢æ¸¬åˆ°çš„ç¼ºé™·å€åŸŸ...")
        red_overlay = np.zeros_like(original_image_for_viz, dtype=np.uint8);
        red_overlay[:] = (0, 0, 255)
        red_mask = cv2.bitwise_and(red_overlay, red_overlay, mask=defect_mask)
        final_image = cv2.addWeighted(original_image_for_viz, 1.0, red_mask, 0.6, 0)
        contours, _ = cv2.findContours(defect_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(final_image, contours, -1, (0, 255, 255), 2)
        cv2.imwrite(cfg.OUTPUT_PATH, final_image)

    print(f"ğŸ‰ æ¨ç†å®Œæˆï¼é«˜ç²¾åº¦çµæœå·²ä¿å­˜è‡³ '{cfg.OUTPUT_PATH}'")


if __name__ == '__main__':
    predict_sliding_window(INFERENCE_CFG)